{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data read\n",
      "data sorted\n",
      "data : 213446\n",
      "dataset created\n",
      "                     stime                    etime             sip  sport  \\\n",
      "0  2017-05-09 10:36:34.876  2017-05-09 11:05:37.894  192.168.80.102   5353   \n",
      "1  2017-05-09 10:38:11.077  2017-05-09 11:06:13.402  192.168.110.60  34056   \n",
      "2  2017-05-09 10:38:11.077  2017-05-09 11:06:13.402  192.168.110.60  34056   \n",
      "3  2017-05-09 10:38:11.077  2017-05-09 11:06:13.402  192.168.110.60  34056   \n",
      "4  2017-05-09 10:38:11.078  2017-05-09 11:06:13.402  192.168.110.60  34056   \n",
      "\n",
      "       sipint                 mac osname osversion fingerprint  \\\n",
      "0  3232256102  20:cf:30:8b:6f:17:                                \n",
      "1  3232263740  00:26:18:f0:62:08:                                \n",
      "2  3232263740  00:26:18:f0:62:08:                                \n",
      "3  3232263740  00:26:18:f0:62:08:                                \n",
      "4  3232263740  00:26:18:f0:62:08:                                \n",
      "\n",
      "               dip     ...     ruflags entropy rentropy tos rtos application  \\\n",
      "0      224.0.0.251     ...           0     108        0  00   00          53   \n",
      "1  171.122.234.240     ...           0     237        0  00   00           0   \n",
      "2  182.132.115.102     ...           0     237        0  00   00           0   \n",
      "3   182.40.209.121     ...           0     237        0  00   00           0   \n",
      "4    124.232.60.77     ...           0     237        0  00   00           0   \n",
      "\n",
      "  vlanint domain endreason        hash  \n",
      "0       0      0    active   876631092  \n",
      "1       0      0       eof  4007369167  \n",
      "2       0      0       eof  4079288409  \n",
      "3       0      0       eof  4085883462  \n",
      "4       0      0       eof   961105778  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "# import csv\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from datetime import datetime\n",
    "\n",
    "file5 = open('201811291521.txt', 'r')\n",
    "dataset = file5.read()\n",
    "print('data read')\n",
    "dataset = dataset.split('\\n')\n",
    "data = []\n",
    "for i in range(0, len(dataset)):\n",
    "    data.append(dataset[i].split('|'))\n",
    "data = sorted(data, key=itemgetter(0))\n",
    "data.pop(0)\n",
    "print('data sorted')\n",
    "\n",
    "headings = ['stime', 'etime', 'sip', 'sport', 'sipint', 'mac', 'osname', 'osversion', 'fingerprint', 'dip', 'dport', 'dipint', 'dstmac', 'rosname', 'rosversion', 'rfingerprint', 'protocol', 'pkts', 'bytes', 'rpkts', 'rbytes', 'dur', 'iflags', 'riflags', 'uflags', 'ruflags', 'entropy', 'rentropy', 'tos', 'rtos', 'application', 'vlanint', 'domain', 'endreason', 'hash']\n",
    "print('data : '+str(len(data)))\n",
    "# for item in data:\n",
    "#     item[0] = datetime.strptime(item[0], '%Y-%m-%d %H:%M:%S.%f')\n",
    "#     item[1] = datetime.strptime(item[1], '%Y-%m-%d %H:%M:%S.%f')\n",
    "#     print(item[0].strftime('%m/%d/%Y'))\n",
    "\n",
    "data = np.array(data)\n",
    "df = pd.DataFrame(data)\n",
    "df.columns = headings\n",
    "print('dataset created')\n",
    "print(df.head())\n",
    "# print(df['protocol'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              sip  sport              dip dport protocol\n",
      "0  192.168.80.102   5353      224.0.0.251  5353       17\n",
      "1  192.168.110.60  34056  171.122.234.240  3395       17\n",
      "2  192.168.110.60  34056  182.132.115.102  3395       17\n",
      "3  192.168.110.60  34056   182.40.209.121  3395       17\n",
      "4  192.168.110.60  34056    124.232.60.77  3395       17\n",
      "4\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sip_0</th>\n",
       "      <th>sip_1</th>\n",
       "      <th>sip_2</th>\n",
       "      <th>sip_3</th>\n",
       "      <th>dip_0</th>\n",
       "      <th>dip_1</th>\n",
       "      <th>dip_2</th>\n",
       "      <th>dip_3</th>\n",
       "      <th>sport</th>\n",
       "      <th>dport</th>\n",
       "      <th>protocol_1</th>\n",
       "      <th>protocol_139</th>\n",
       "      <th>protocol_17</th>\n",
       "      <th>protocol_2</th>\n",
       "      <th>protocol_41</th>\n",
       "      <th>protocol_47</th>\n",
       "      <th>protocol_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192</td>\n",
       "      <td>168</td>\n",
       "      <td>080</td>\n",
       "      <td>102</td>\n",
       "      <td>224</td>\n",
       "      <td>000</td>\n",
       "      <td>000</td>\n",
       "      <td>251</td>\n",
       "      <td>5353</td>\n",
       "      <td>5353</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192</td>\n",
       "      <td>168</td>\n",
       "      <td>110</td>\n",
       "      <td>060</td>\n",
       "      <td>171</td>\n",
       "      <td>122</td>\n",
       "      <td>234</td>\n",
       "      <td>240</td>\n",
       "      <td>34056</td>\n",
       "      <td>3395</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>192</td>\n",
       "      <td>168</td>\n",
       "      <td>110</td>\n",
       "      <td>060</td>\n",
       "      <td>182</td>\n",
       "      <td>132</td>\n",
       "      <td>115</td>\n",
       "      <td>102</td>\n",
       "      <td>34056</td>\n",
       "      <td>3395</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192</td>\n",
       "      <td>168</td>\n",
       "      <td>110</td>\n",
       "      <td>060</td>\n",
       "      <td>182</td>\n",
       "      <td>040</td>\n",
       "      <td>209</td>\n",
       "      <td>121</td>\n",
       "      <td>34056</td>\n",
       "      <td>3395</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>192</td>\n",
       "      <td>168</td>\n",
       "      <td>110</td>\n",
       "      <td>060</td>\n",
       "      <td>124</td>\n",
       "      <td>232</td>\n",
       "      <td>060</td>\n",
       "      <td>077</td>\n",
       "      <td>34056</td>\n",
       "      <td>3395</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sip_0 sip_1 sip_2 sip_3 dip_0 dip_1 dip_2 dip_3  sport dport  protocol_1  \\\n",
       "0   192   168   080   102   224   000   000   251   5353  5353           0   \n",
       "1   192   168   110   060   171   122   234   240  34056  3395           0   \n",
       "2   192   168   110   060   182   132   115   102  34056  3395           0   \n",
       "3   192   168   110   060   182   040   209   121  34056  3395           0   \n",
       "4   192   168   110   060   124   232   060   077  34056  3395           0   \n",
       "\n",
       "   protocol_139  protocol_17  protocol_2  protocol_41  protocol_47  protocol_6  \n",
       "0             0            1           0            0            0           0  \n",
       "1             0            1           0            0            0           0  \n",
       "2             0            1           0            0            0           0  \n",
       "3             0            1           0            0            0           0  \n",
       "4             0            1           0            0            0           0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edited_df = df.drop(['stime','etime','sipint','mac','osname','osversion','fingerprint','dipint','dstmac','rosname','rosversion','rfingerprint','iflags','riflags','uflags','ruflags','entropy','rentropy','tos','rtos','application','vlanint','domain','hash','pkts','bytes','rpkts','rbytes','dur','endreason'],axis=1)\n",
    "print(edited_df.head())\n",
    "# Get one hot encoding of columns B\n",
    "one_hot = pd.get_dummies(edited_df['protocol'])\n",
    "# Drop column B as it is now encoded\n",
    "edited_df = edited_df.drop('protocol',axis = 1)\n",
    "headers = []\n",
    "for i in one_hot.columns:\n",
    "    headers.append('protocol_' + i)\n",
    "# Join the encoded df\n",
    "\n",
    "one_hot.columns = headers\n",
    "# edited_df = edited_df.join(one_hot)\n",
    "\n",
    "def correct_ip(s):\n",
    "    o = ''\n",
    "    if '.' in s:\n",
    "        for part in s.split('.'):\n",
    "            part = part.zfill(3)\n",
    "            o += part \n",
    "    else:\n",
    "        o = o.zfill(12)\n",
    "    o = o[:3] + '.' + o[3:]\n",
    "    o = o[:7] + '.' + o[7:]\n",
    "    o = o[:11] + '.' + o[11:]\n",
    "    return o\n",
    "\n",
    "def correct_port(s):\n",
    "    return(s.zfill(5))\n",
    "        \n",
    "\n",
    "\n",
    "sip_headers = []\n",
    "dip_headers = []\n",
    "\n",
    "for i in range(4):\n",
    "    sip_headers.append('sip_'+str(i))\n",
    "    dip_headers.append('dip_'+str(i))\n",
    "\n",
    "sip = []\n",
    "for ip in edited_df['sip']:\n",
    "#     print(correct_ip(ip).split('.'))\n",
    "    sip.append(correct_ip(ip).split('.'))\n",
    "\n",
    "dip = []\n",
    "for ip in edited_df['dip']:\n",
    "#     print(ip)\n",
    "    dip.append(correct_ip(ip).split('.'))\n",
    "        \n",
    "print(len(sip[0]))\n",
    "print(len(dip[0]))\n",
    "# print(len(dport[0]))\n",
    "# print(len(sport[0]))\n",
    "8\n",
    "sip_df = pd.DataFrame(sip,columns=sip_headers)\n",
    "dip_df = pd.DataFrame(dip,columns=dip_headers)\n",
    "# sport_df = edited_df[]\n",
    "\n",
    "result = pd.concat([sip_df, dip_df, edited_df['sport'], edited_df['dport'], one_hot], axis=1, sort=False)\n",
    "result.head()\n",
    "# sport_df\n",
    "# edited_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:64: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [6] vs. [32]\n\t [[{{node training_4/Adam/gradients/loss_5/dense_30_loss/mul_1_grad/BroadcastGradientArgs}} = BroadcastGradientArgs[T=DT_INT32, _class=[\"loc:@training_4/Adam/gradients/loss_5/dense_30_loss/mul_1_grad/Reshape\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](training_4/Adam/gradients/loss_5/dense_30_loss/mul_1_grad/Shape, training_4/Adam/gradients/loss_5/dense_30_loss/mul_1_grad/Shape_1)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3919f7a03b68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvae_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [6] vs. [32]\n\t [[{{node training_4/Adam/gradients/loss_5/dense_30_loss/mul_1_grad/BroadcastGradientArgs}} = BroadcastGradientArgs[T=DT_INT32, _class=[\"loc:@training_4/Adam/gradients/loss_5/dense_30_loss/mul_1_grad/Reshape\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](training_4/Adam/gradients/loss_5/dense_30_loss/mul_1_grad/Shape, training_4/Adam/gradients/loss_5/dense_30_loss/mul_1_grad/Shape_1)]]"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras.models import Model\n",
    "from keras.objectives import binary_crossentropy\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "m = 6\n",
    "n_z = 2\n",
    "n_epoch = 10\n",
    "\n",
    "input_size = 17\n",
    "hidden_size = 8\n",
    "\n",
    "\n",
    "# Q(z|X) -- encoder\n",
    "inputs = Input(shape=(input_size,))\n",
    "h_q = Dense(hidden_size, activation='relu')(inputs)\n",
    "mu = Dense(n_z, activation='linear')(h_q)\n",
    "log_sigma = Dense(n_z, activation='linear')(h_q)\n",
    "\n",
    "def sample_z(args):\n",
    "    mu, log_sigma = args\n",
    "    eps = K.random_normal(shape=(m, n_z), mean=0., stddev=1.)\n",
    "    return mu + K.exp(log_sigma / 2) * eps\n",
    "\n",
    "\n",
    "# Sample z ~ Q(z|X)\n",
    "z = Lambda(sample_z)([mu, log_sigma])\n",
    "# P(X|z) -- decoder\n",
    "decoder_hidden = Dense(hidden_size, activation='relu')\n",
    "decoder_out = Dense(input_size, activation='sigmoid')\n",
    "\n",
    "h_p = decoder_hidden(z)\n",
    "outputs = decoder_out(h_p)\n",
    "\n",
    "# Overall VAE model, for reconstruction and training\n",
    "vae = Model(inputs, outputs)\n",
    "\n",
    "# Encoder model, to encode input into latent variable\n",
    "# We use the mean as the output as it is the center point, the representative of the gaussian\n",
    "encoder = Model(inputs, mu)\n",
    "\n",
    "# Generator model, generate new data given latent variable z\n",
    "d_in = Input(shape=(n_z,))\n",
    "d_h = decoder_hidden(d_in)\n",
    "d_out = decoder_out(d_h)\n",
    "decoder = Model(d_in, d_out)\n",
    "\n",
    "def vae_loss(y_true, y_pred):\n",
    "    \"\"\" Calculate loss = reconstruction loss + KL loss for each data in minibatch \"\"\"\n",
    "    # E[log P(X|z)]\n",
    "    recon = K.sum(K.binary_crossentropy(y_pred, y_true), axis=1)\n",
    "    # D_KL(Q(z|X) || P(z|X)); calculate in closed form as both dist. are Gaussian\n",
    "    kl = 0.5 * K.sum(K.exp(log_sigma) + K.square(mu) - 1. - log_sigma, axis=1)\n",
    "\n",
    "    return recon + kl\n",
    "\n",
    "vae.compile(optimizer='adam', loss=vae_loss)\n",
    "vae.fit(result, result, batch_size=m, nb_epoch=n_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
