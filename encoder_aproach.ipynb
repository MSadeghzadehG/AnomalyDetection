{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data read\n",
      "data sorted\n",
      "data : 213446\n",
      "dataset created\n",
      "                     stime                    etime             sip  sport  \\\n",
      "0  2017-05-09 10:36:34.876  2017-05-09 11:05:37.894  192.168.80.102   5353   \n",
      "1  2017-05-09 10:38:11.077  2017-05-09 11:06:13.402  192.168.110.60  34056   \n",
      "2  2017-05-09 10:38:11.077  2017-05-09 11:06:13.402  192.168.110.60  34056   \n",
      "3  2017-05-09 10:38:11.077  2017-05-09 11:06:13.402  192.168.110.60  34056   \n",
      "4  2017-05-09 10:38:11.078  2017-05-09 11:06:13.402  192.168.110.60  34056   \n",
      "\n",
      "       sipint                 mac osname osversion fingerprint  \\\n",
      "0  3232256102  20:cf:30:8b:6f:17:                                \n",
      "1  3232263740  00:26:18:f0:62:08:                                \n",
      "2  3232263740  00:26:18:f0:62:08:                                \n",
      "3  3232263740  00:26:18:f0:62:08:                                \n",
      "4  3232263740  00:26:18:f0:62:08:                                \n",
      "\n",
      "               dip     ...     ruflags entropy rentropy tos rtos application  \\\n",
      "0      224.0.0.251     ...           0     108        0  00   00          53   \n",
      "1  171.122.234.240     ...           0     237        0  00   00           0   \n",
      "2  182.132.115.102     ...           0     237        0  00   00           0   \n",
      "3   182.40.209.121     ...           0     237        0  00   00           0   \n",
      "4    124.232.60.77     ...           0     237        0  00   00           0   \n",
      "\n",
      "  vlanint domain endreason        hash  \n",
      "0       0      0    active   876631092  \n",
      "1       0      0       eof  4007369167  \n",
      "2       0      0       eof  4079288409  \n",
      "3       0      0       eof  4085883462  \n",
      "4       0      0       eof   961105778  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "# import csv\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "\n",
    "# from datetime import datetime\n",
    "\n",
    "file5 = open('201811291521.txt', 'r')\n",
    "dataset = file5.read()\n",
    "print('data read')\n",
    "dataset = dataset.split('\\n')\n",
    "data = []\n",
    "for i in range(0, len(dataset)):\n",
    "    data.append(dataset[i].split('|'))\n",
    "data = sorted(data, key=itemgetter(0))\n",
    "data.pop(0)\n",
    "print('data sorted')\n",
    "\n",
    "headings = ['stime', 'etime', 'sip', 'sport', 'sipint', 'mac', 'osname', 'osversion', 'fingerprint', 'dip', 'dport', 'dipint', 'dstmac', 'rosname', 'rosversion', 'rfingerprint', 'protocol', 'pkts', 'bytes', 'rpkts', 'rbytes', 'dur', 'iflags', 'riflags', 'uflags', 'ruflags', 'entropy', 'rentropy', 'tos', 'rtos', 'application', 'vlanint', 'domain', 'endreason', 'hash']\n",
    "print('data : '+str(len(data)))\n",
    "# for item in data:\n",
    "#     item[0] = datetime.strptime(item[0], '%Y-%m-%d %H:%M:%S.%f')\n",
    "#     item[1] = datetime.strptime(item[1], '%Y-%m-%d %H:%M:%S.%f')\n",
    "#     print(item[0].strftime('%m/%d/%Y'))\n",
    "\n",
    "data = np.array(data)\n",
    "df = pd.DataFrame(data)\n",
    "df.columns = headings\n",
    "print('dataset created')\n",
    "print(df.head())\n",
    "# print(df['protocol'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              sip  sport              dip dport protocol\n",
      "0  192.168.80.102   5353      224.0.0.251  5353       17\n",
      "1  192.168.110.60  34056  171.122.234.240  3395       17\n",
      "2  192.168.110.60  34056  182.132.115.102  3395       17\n",
      "3  192.168.110.60  34056   182.40.209.121  3395       17\n",
      "4  192.168.110.60  34056    124.232.60.77  3395       17\n",
      "213446\n"
     ]
    }
   ],
   "source": [
    "edited_df = df.drop(['stime','etime','sipint','mac','osname','osversion','fingerprint','dipint','dstmac','rosname','rosversion','rfingerprint','iflags','riflags','uflags','ruflags','entropy','rentropy','tos','rtos','application','vlanint','domain','hash','pkts','bytes','rpkts','rbytes','dur','endreason'],axis=1)\n",
    "print(edited_df.head())\n",
    "# Get one hot encoding of columns B\n",
    "one_hot = pd.get_dummies(edited_df['protocol'])\n",
    "# Drop column B as it is now encoded\n",
    "edited_df = edited_df.drop('protocol',axis = 1)\n",
    "headers = []\n",
    "for i in one_hot.columns:\n",
    "    headers.append('protocol_' + i)\n",
    "# Join the encoded df\n",
    "\n",
    "one_hot.columns = headers\n",
    "# edited_df = edited_df.join(one_hot)\n",
    "\n",
    "def correct_ip(s):\n",
    "    o = ''\n",
    "    if '.' in s:\n",
    "        for part in s.split('.'):\n",
    "            part = part.zfill(3)\n",
    "            o += part \n",
    "    else:\n",
    "        o = o.zfill(12)\n",
    "    o = o[:3] + '.' + o[3:]\n",
    "    o = o[:7] + '.' + o[7:]\n",
    "    o = o[:11] + '.' + o[11:]\n",
    "    return o\n",
    "\n",
    "def correct_port(s):\n",
    "    return(s.zfill(5))\n",
    "        \n",
    "\n",
    "\n",
    "sip_headers = []\n",
    "dip_headers = []\n",
    "\n",
    "for i in range(4):\n",
    "    sip_headers.append('sip_'+str(i))\n",
    "    dip_headers.append('dip_'+str(i))\n",
    "\n",
    "sip = []\n",
    "for ip in edited_df['sip']:\n",
    "    sip.append(map(str,correct_ip(ip).split('.')))\n",
    "#     sip.append(correct_ip(ip).split('.'))\n",
    "\n",
    "dip = []\n",
    "for ip in edited_df['dip']:\n",
    "    dip.append(map(str,correct_ip(ip).split('.')))\n",
    "#     dip.append(correct_ip(ip).split('.'))\n",
    "\n",
    "\n",
    "        \n",
    "sport = []\n",
    "for port in edited_df['sport']:\n",
    "    sport.append(int(port))\n",
    "    \n",
    "dport = []\n",
    "for port in edited_df['dport']:\n",
    "    dport.append(int(port))\n",
    "# print(len(sip[0]))\n",
    "# print(len(dip[0]))\n",
    "# print(len(dport[0]))\n",
    "# print(len(sport[0]))\n",
    "8\n",
    "sip_df = pd.DataFrame(sip,columns=sip_headers)\n",
    "dip_df = pd.DataFrame(dip,columns=dip_headers)\n",
    "sport_df = pd.DataFrame(sport,columns=['sport'])\n",
    "dport_df = pd.DataFrame(sport,columns=['dport'])\n",
    "\n",
    "\n",
    "result = pd.concat([sip_df, dip_df, sport_df, dport_df, one_hot], axis=1, sort=False)\n",
    "result.head()\n",
    "result.describe()\n",
    "print(len(result.values))\n",
    "# sport_df\n",
    "# edited_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.layers import Input, Dense, Lambda\n",
    "# from keras.models import Model\n",
    "# from keras.objectives import binary_crossentropy\n",
    "# from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import keras.backend as K\n",
    "# import tensorflow as tf\n",
    "\n",
    "\n",
    "# m = 6\n",
    "# n_z = 2\n",
    "# n_epoch = 10\n",
    "\n",
    "# input_size = 17\n",
    "# hidden_size = 8\n",
    "\n",
    "\n",
    "# # Q(z|X) -- encoder\n",
    "# inputs = Input(shape=(input_size,))\n",
    "# h_q = Dense(hidden_size, activation='relu')(inputs)\n",
    "# mu = Dense(n_z, activation='linear')(h_q)\n",
    "# log_sigma = Dense(n_z, activation='linear')(h_q)\n",
    "\n",
    "# def sample_z(args):\n",
    "#     mu, log_sigma = args\n",
    "#     eps = K.random_normal(shape=(m, n_z), mean=0., stddev=1.)\n",
    "#     return mu + K.exp(log_sigma / 2) * eps\n",
    "\n",
    "\n",
    "# # Sample z ~ Q(z|X)\n",
    "# z = Lambda(sample_z)([mu, log_sigma])\n",
    "# # P(X|z) -- decoder\n",
    "# decoder_hidden = Dense(hidden_size, activation='relu')\n",
    "# decoder_out = Dense(input_size, activation='sigmoid')\n",
    "\n",
    "# h_p = decoder_hidden(z)\n",
    "# outputs = decoder_out(h_p)\n",
    "\n",
    "# # Overall VAE model, for reconstruction and training\n",
    "# vae = Model(inputs, outputs)\n",
    "\n",
    "# # Encoder model, to encode input into latent variable\n",
    "# # We use the mean as the output as it is the center point, the representative of the gaussian\n",
    "# encoder = Model(inputs, mu)\n",
    "\n",
    "# # Generator model, generate new data given latent variable z\n",
    "# d_in = Input(shape=(n_z,))\n",
    "# d_h = decoder_hidden(d_in)\n",
    "# d_out = decoder_out(d_h)\n",
    "# decoder = Model(d_in, d_out)\n",
    "\n",
    "# def vae_loss(y_true, y_pred):\n",
    "#     \"\"\" Calculate loss = reconstruction loss + KL loss for each data in minibatch \"\"\"\n",
    "#     # E[log P(X|z)]\n",
    "#     recon = K.sum(K.binary_crossentropy(y_pred, y_true), axis=1)\n",
    "#     # D_KL(Q(z|X) || P(z|X)); calculate in closed form as both dist. are Gaussian\n",
    "#     kl = 0.5 * K.sum(K.exp(log_sigma) + K.square(mu) - 1. - log_sigma, axis=1)\n",
    "\n",
    "#     return recon + kl\n",
    "\n",
    "# vae.compile(optimizer='adam', loss=vae_loss)\n",
    "# vae.fit(result, result, batch_size=m, nb_epoch=n_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(170756, 17) (42690, 17)\n",
      "Running Fold 1 / 10\n",
      "Train on 153681 samples, validate on 17075 samples\n",
      "Epoch 1/10\n",
      "153681/153681 [==============================] - 5s 34us/step - loss: 286337.5590 - acc: 0.1514 - val_loss: 136637.2880 - val_acc: 0.1464\n",
      "Epoch 2/10\n",
      "153681/153681 [==============================] - 4s 24us/step - loss: 124352.5787 - acc: 0.2752 - val_loss: 108965.9604 - val_acc: 0.6624\n",
      "Epoch 3/10\n",
      "153681/153681 [==============================] - 4s 24us/step - loss: 108746.2916 - acc: 0.8284 - val_loss: 108935.1999 - val_acc: 0.9806\n",
      "Epoch 4/10\n",
      "153681/153681 [==============================] - 4s 24us/step - loss: 78250.2376 - acc: 0.9805 - val_loss: 71883.6288 - val_acc: 0.9808\n",
      "Epoch 5/10\n",
      "153681/153681 [==============================] - 4s 24us/step - loss: 71754.0104 - acc: 0.9805 - val_loss: 71871.0381 - val_acc: 0.9808\n",
      "Epoch 6/10\n",
      "153681/153681 [==============================] - 4s 24us/step - loss: 71739.0908 - acc: 0.9805 - val_loss: 71853.8855 - val_acc: 0.9808\n",
      "Epoch 7/10\n",
      "153681/153681 [==============================] - 4s 24us/step - loss: 71725.7227 - acc: 0.9805 - val_loss: 71845.8830 - val_acc: 0.9808\n",
      "Epoch 8/10\n",
      "153681/153681 [==============================] - 4s 24us/step - loss: 71714.1375 - acc: 0.9805 - val_loss: 71829.9875 - val_acc: 0.9808\n",
      "Epoch 9/10\n",
      "153681/153681 [==============================] - 4s 24us/step - loss: 71703.3618 - acc: 0.9805 - val_loss: 71823.6728 - val_acc: 0.9808\n",
      "Epoch 10/10\n",
      "153681/153681 [==============================] - 4s 24us/step - loss: 71689.7154 - acc: 0.9805 - val_loss: 71802.6090 - val_acc: 0.9808\n",
      "fold validation score =  [71802.60987326135, 0.9807906295754026]\n",
      "Running Fold 2 / 10\n",
      "Train on 153681 samples, validate on 17075 samples\n",
      "Epoch 1/10\n",
      "153681/153681 [==============================] - 4s 24us/step - loss: 71700.5986 - acc: 0.9806 - val_loss: 71558.1677 - val_acc: 0.9800\n",
      "Epoch 2/10\n",
      "153681/153681 [==============================] - 4s 24us/step - loss: 71682.2317 - acc: 0.9806 - val_loss: 71548.4300 - val_acc: 0.9800\n",
      "Epoch 3/10\n",
      " 16384/153681 [==>...........................] - ETA: 3s - loss: 71771.1063 - acc: 0.9794"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#     print(row)\n",
    "x_train,x_test = train_test_split(result, test_size=0.2)\n",
    "print(x_train.shape, x_test.shape)\n",
    "\n",
    "# kf = KFold(n_splits=2) # Define the split - into 2 folds \n",
    "# kf.get_n_splits(x_train) # returns the number of splitting iterations in the cross-validator\n",
    "# print(kf) \n",
    "# KFold(n_splits=2, random_state=None, shuffle=False)\n",
    "\n",
    "# loo = LeaveOneOut()\n",
    "# loo.get_n_splits(X)\n",
    "\n",
    "\n",
    "\n",
    "input_d = Input(shape=(17,))\n",
    "encoded = Dense(14, activation='relu')(input_d)\n",
    "encoded = Dense(10, activation='relu')(encoded)\n",
    "encoded = Dense(6, activation='relu')(encoded)\n",
    "encoded = Dense(3, activation='relu')(encoded)\n",
    "\n",
    "decoded = Dense(6, activation='relu')(encoded)\n",
    "decoded = Dense(10, activation='relu')(decoded)\n",
    "decoded = Dense(14, activation='relu')(decoded)\n",
    "decoded = Dense(17, activation='sigmoid')(decoded)\n",
    "\n",
    "autoencoder = Model(input_d, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "n_folds = 10\n",
    "fold_len = int(len(x_train)/n_folds)\n",
    "cross_validation_scores = []\n",
    "for i in range(n_folds):\n",
    "    print(\"Running Fold\", i+1, \"/\", n_folds)\n",
    "    fold_train = [k for k in range(0,i*fold_len)] + [k for k in range((i+1)*fold_len,len(x_train))]\n",
    "    fold_test = [item for item in range(i*fold_len,(i+1)*fold_len)]\n",
    "    test = x_train.iloc[fold_test]\n",
    "    train = x_train.iloc[fold_train]\n",
    "    autoencoder.fit(train, train,\n",
    "            epochs=10,\n",
    "            batch_size=256,\n",
    "            shuffle=True,\n",
    "            validation_data = (test,test))\n",
    "    fold_validation_score = autoencoder.evaluate(test,test,verbose=0)\n",
    "    print(\"fold validation score = \", fold_validation_score)\n",
    "    cross_validation_scores.append(fold_validation_score[1] * 100)\n",
    "\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cross_validation_scores), np.std(cross_validation_scores)))\n",
    "autoencoder.evaluate(x=x_test,y=x_test)    \n",
    "    \n",
    "# autoencoder.fit(x_train, x_train,\n",
    "#             epochs=100,\n",
    "#             batch_size=256,\n",
    "#             shuffle=True,\n",
    "#             validation_split = 0.2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sip_0            192\n",
      "sip_1            168\n",
      "sip_2            080\n",
      "sip_3            102\n",
      "dip_0            224\n",
      "dip_1            000\n",
      "dip_2            000\n",
      "dip_3            251\n",
      "sport           5353\n",
      "dport           5353\n",
      "protocol_1         0\n",
      "protocol_139       0\n",
      "protocol_17        1\n",
      "protocol_2         0\n",
      "protocol_41        0\n",
      "protocol_47        0\n",
      "protocol_6         0\n",
      "Name: 0, dtype: object\n",
      "['192' '168' '080' '102' '224' '000' '000' '251' '5353' '5353' 0 0 1 0 0 0\n",
      " 0]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_35 to have shape (17,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-946c287ab3e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mlist_of_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_35 to have shape (17,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "list_of_loss = []#autoencoder.predict()\n",
    "print(result.iloc[0])\n",
    "for index, row in result.iterrows():\n",
    "    print(result.iloc[index].values)\n",
    "    list_of_loss.append(autoencoder.evaluate(row,row,verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
